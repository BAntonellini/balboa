daily_morning_bluegreen_run:
  description: "Bluegreen run at 7am"
  schedule_interval: "01 6 * * *"
  default_args:
    start_date: 2021-01-01
  catchup: False
  task_groups:
    extract_and_load:
      tooltip: "Extract and Load tasks"
  tasks:
    load:
      generator: dagfactory.AirbyteDbtGenerator
      airflow_connection_id: airbyte_connection
      dbt_project_path: transform
      deploy_path: /tmp/load
      task_group_name: extract_and_load
      virtualenv_path: /opt/datacoves/virtualenvs/main
      # Update tag for job
      run_dbt_compile: false
      dbt_list_args: "--select tag:daily_morning"
    transform:
      operator: airflow.operators.bash_operator.BashOperator
      executor_config:
        pod_override:
          api_version: False
          kind: False
          metadata: False
          spec:
            active_deadline_seconds: False
            affinity: False
            automount_service_account_token: False
            containers:
              - args: False
                command: False
                env: False
                env_from: False
                image: datacoves/airflow-pandas:latest
                image_pull_policy: False
                lifecycle: False
                liveness_probe: False
                name: base
                ports: False
                readiness_probe: False
                resources: False
                security_context: False
                startup_probe: False
                stdin: False
                stdin_once: False
                termination_message_path: False
                termination_message_policy: False
                tty: False
                volume_devices: False
                volume_mounts: False
                working_dir: False
            dns_config: False
            dns_policy: False
            enable_service_links: False
            ephemeral_containers: False
            host_aliases: False
            host_ipc: False
            host_network: False
            host_pid: False
            hostname: False
            image_pull_secrets: False
            init_containers: False
            node_name: False
            node_selector: False
            os: False
            overhead: False
            preemption_policy: False
            priority: False
            priority_class_name: False
            readiness_gates: False
            restart_policy: False
            runtime_class_name: False
            scheduler_name: False
            security_context: False
            service_account: False
            service_account_name: False
            set_hostname_as_fqdn: False
            share_process_namespace: False
            subdomain: False
            termination_grace_period_seconds: False
            tolerations: False
            topology_spread_constraints: False
            volumes: False
          status: False
      # Example of how to set Airflow vars as ENV vars
      env:
        DBT_USER: "{{ var.value.DBT_USER }}"
      # Update tag for job
      bash_command: "python $DATACOVES__REPO_PATH/automate/blue_green_run.py --production-run -s tag:daily_morning"
      dependencies: ["extract_and_load"]
