daily_morning_bluegreen_run:
  description: "Bluegreen run at 7am"
  schedule_interval: "01 6 * * *"
  default_args:
    start_date: 2021-01-01
  catchup: False
  task_groups:
    extract_and_load:
      tooltip: "Extract and Load tasks"
  tasks:
    load:
      generator: dagfactory.AirbyteDbtGenerator
      airflow_connection_id: airbyte_connection
      dbt_project_path: transform
      deploy_path: /tmp/load
      task_group_name: extract_and_load
      virtualenv_path: /opt/datacoves/virtualenvs/main
      # Update tag for job
      run_dbt_compile: false
      dbt_list_args: "--select tag:daily_morning"
    transform:
      operator: airflow.operators.bash_operator.BashOperator
      executor_config:
        pod_override:
          api_version:
          kind:
          metadata:
          spec:
            active_deadline_seconds:
            affinity:
            automount_service_account_token:
            containers:
              - args:
                command:
                env:
                env_from:
                image: datacoves/airflow-pandas:latest
                image_pull_policy:
                lifecycle:
                liveness_probe:
                name: base
                ports:
                readiness_probe:
                resources:
                security_context:
                startup_probe:
                stdin:
                stdin_once:
                termination_message_path:
                termination_message_policy:
                tty:
                volume_devices:
                volume_mounts:
                working_dir:
            dns_config:
            dns_policy:
            enable_service_links:
            ephemeral_containers:
            host_aliases:
            host_ipc:
            host_network:
            host_pid:
            hostname:
            image_pull_secrets:
            init_containers:
            node_name:
            node_selector:
            os:
            overhead:
            preemption_policy:
            priority:
            priority_class_name:
            readiness_gates:
            restart_policy:
            runtime_class_name:
            scheduler_name:
            security_context:
            service_account:
            service_account_name:
            set_hostname_as_fqdn:
            share_process_namespace:
            subdomain:
            termination_grace_period_seconds:
            tolerations:
            topology_spread_constraints:
            volumes:
          status:
      # Example of how to set Airflow vars as ENV vars
      # env:
      #   DBT_USER: "{{ var.value.DBT_USER }}"
      # Update tag for job
      bash_command: "python $DATACOVES__REPO_PATH/automate/blue_green_run.py --production-run -s tag:daily_morning"
      dependencies: ["extract_and_load"]
